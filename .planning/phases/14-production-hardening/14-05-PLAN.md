---
phase: 14-production-hardening
plan: 05
type: execute
wave: 2
depends_on: []
files_modified:
  - src/middleware/rateLimiter.ts
  - src/config/redis.ts
  - src/routes/index.ts
  - src/webhooks/alert-receiver.ts
autonomous: true

must_haves:
  truths:
    - "Rate limiting uses Redis for distributed state"
    - "Webhook endpoints allow 1000 req/min per IP"
    - "API endpoints allow 500 req/min per authenticated user"
    - "Public endpoints allow 100 req/min per IP"
    - "Rate limit headers returned on all responses"
    - "Rate limit violations logged to audit system"
  artifacts:
    - path: "src/middleware/rateLimiter.ts"
      provides: "Redis-backed rate limiting middleware"
      contains: "RateLimiterRedis"
    - path: "src/middleware/rateLimiter.ts"
      provides: "Rate limit tiers"
      contains: "webhookLimiter"
  key_links:
    - from: "src/middleware/rateLimiter.ts"
      to: "src/config/redis.ts"
      via: "Redis client"
      pattern: "redisClient"
    - from: "src/routes/index.ts"
      to: "src/middleware/rateLimiter.ts"
      via: "middleware application"
      pattern: "apiRateLimiter"
---

<objective>
Implement Redis-backed rate limiting for all API endpoints with tiered limits for webhooks, authenticated APIs, and public endpoints.

Purpose: Current rate limiting is memory-based, which doesn't work across multiple server instances and loses state on restart. Production requires Redis-backed rate limiting for consistent enforcement.

Output: Redis-backed rate limiters with appropriate tiers and standard rate limit headers on all responses.
</objective>

<execution_context>
@/Users/tvellore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tvellore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Existing rate limiter
@src/middleware/rateLimiter.ts
# Redis configuration
@src/config/redis.ts
# Route registration
@src/routes/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Redis-backed rate limiters with tiers</name>
  <files>
    src/middleware/rateLimiter.ts
    src/config/redis.ts
  </files>
  <action>
    Refactor src/middleware/rateLimiter.ts to use Redis:

    1. Import RateLimiterRedis from rate-limiter-flexible (already installed)
    2. Import Redis client from src/config/redis.ts (verify ioredis client export)

    3. Create tiered rate limiters:
       ```typescript
       // Webhook tier: 1000 req/min per IP (high volume from monitoring tools)
       const webhookLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:webhook',
         points: 1000,
         duration: 60,
       });

       // API tier: 500 req/min per authenticated user
       const apiLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:api',
         points: 500,
         duration: 60,
       });

       // Public tier: 100 req/min per IP (unauthenticated)
       const publicLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:public',
         points: 100,
         duration: 60,
       });

       // Keep memory-based break-glass limiter (emergency fallback if Redis down)
       ```

    4. Verify src/config/redis.ts exports a usable Redis client:
       - Check if ioredis client is exported
       - If not, add export for rate limiter use

    5. Add graceful fallback: if Redis unavailable, log warning and allow request
       (avoid blocking all traffic on Redis failure)
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check rate limiters use RateLimiterRedis
    Verify redis client import works
  </verify>
  <done>
    Three Redis-backed rate limiters created with appropriate limits per tier.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create rate limit middleware with headers</name>
  <files>
    src/middleware/rateLimiter.ts
  </files>
  <action>
    Create Express middleware functions that:

    1. Apply correct limiter based on route/auth status:
       ```typescript
       export function webhookRateLimiter(req, res, next) {
         const key = req.ip || 'unknown';
         webhookLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 1000);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'webhook');
           });
       }

       export function apiRateLimiter(req, res, next) {
         // Use user ID for authenticated requests, IP for anonymous
         const key = req.user?.id || req.ip || 'unknown';
         apiLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 500);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'api');
           });
       }

       export function publicRateLimiter(req, res, next) {
         const key = req.ip || 'unknown';
         publicLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 100);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'public');
           });
       }
       ```

    2. Set standard rate limit headers:
       ```typescript
       function setRateLimitHeaders(res, rateLimiterRes, limit) {
         res.set({
           'X-RateLimit-Limit': limit,
           'X-RateLimit-Remaining': rateLimiterRes.remainingPoints,
           'X-RateLimit-Reset': Math.ceil(Date.now() / 1000) + Math.ceil(rateLimiterRes.msBeforeNext / 1000)
         });
       }
       ```

    3. Handle rate limit exceeded:
       ```typescript
       async function handleRateLimitExceeded(req, res, rateLimiterRes, tier) {
         const secs = Math.ceil(rateLimiterRes.msBeforeNext / 1000);

         await auditService.log({
           action: 'rate_limit.exceeded',
           severity: 'WARN',
           userId: req.user?.id,
           metadata: {
             tier,
             ip: req.ip,
             path: req.path,
             retryAfter: secs
           }
         });

         res.set({
           'Retry-After': secs,
           'X-RateLimit-Limit': limit,
           'X-RateLimit-Remaining': 0,
           'X-RateLimit-Reset': Math.ceil(Date.now() / 1000) + secs
         });

         res.status(429).json({
           error: 'Too Many Requests',
           message: 'Rate limit exceeded',
           retryAfter: secs
         });
       }
       ```
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check all three middleware functions exported
    Verify headers are set correctly
  </verify>
  <done>
    Rate limit middleware functions with standard headers and audit logging.
  </done>
</task>

<task type="auto">
  <name>Task 3: Apply rate limiters to routes</name>
  <files>
    src/routes/index.ts
    src/webhooks/alert-receiver.ts
  </files>
  <action>
    Apply rate limiters to appropriate routes:

    1. Update src/webhooks/alert-receiver.ts:
       - Add webhookRateLimiter as first middleware on webhook routes
       - Ensure it runs before signature verification

    2. Update src/routes/index.ts or main route file:
       - Apply apiRateLimiter to /api/* routes (authenticated)
       - Apply publicRateLimiter to public endpoints (status pages, health checks)

    3. Route classification:
       - Webhooks (/webhooks/*): webhookRateLimiter (1000/min)
       - API (/api/*): apiRateLimiter (500/min per user)
       - Public (/status/*, /health): publicRateLimiter (100/min)
       - Auth (/auth/*): Keep existing loginRateLimiter for break-glass

    4. Ensure rate limit middleware runs early in the chain (before auth for webhooks)

    5. Add comments documenting rate limit tiers for future reference

    Note: Don't double-apply limiters. Check if route already has rate limiting.
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check webhook routes use webhookRateLimiter
    Check API routes use apiRateLimiter
    Manual test: make requests and verify X-RateLimit-* headers in response
  </verify>
  <done>
    Rate limiters applied to all routes with appropriate tiers.
  </done>
</task>

</tasks>

<verification>
1. Rate limiters use Redis (not memory)
2. Three tiers configured correctly
3. Standard headers on all responses
4. 429 response on limit exceeded
5. Audit logging for violations
6. TypeScript builds without errors
</verification>

<success_criteria>
- [ ] RateLimiterRedis used for all tiers
- [ ] Webhooks: 1000 req/min per IP
- [ ] API: 500 req/min per user
- [ ] Public: 100 req/min per IP
- [ ] X-RateLimit-* headers on responses
- [ ] Violations logged to audit system
- [ ] Graceful fallback on Redis failure
</success_criteria>

<output>
After completion, create `.planning/phases/14-production-hardening/14-05-SUMMARY.md`
</output>
