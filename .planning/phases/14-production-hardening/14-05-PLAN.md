---
phase: 14-production-hardening
plan: 05
type: execute
wave: 1
depends_on: []
files_modified:
  - src/middleware/rateLimiter.ts
  - src/config/redis.ts
  - src/index.ts
  - src/webhooks/alert-receiver.ts
autonomous: true

must_haves:
  truths:
    - "Rate limiting uses Redis for distributed state"
    - "Webhook endpoints allow 1000 req/min per IP"
    - "API endpoints allow 500 req/min per authenticated user"
    - "Public endpoints allow 100 req/min per IP"
    - "Rate limit headers returned on all responses"
    - "Rate limit violations logged to audit system"
  artifacts:
    - path: "src/middleware/rateLimiter.ts"
      provides: "Redis-backed rate limiting middleware"
      contains: "RateLimiterRedis"
    - path: "src/middleware/rateLimiter.ts"
      provides: "Rate limit tiers"
      contains: "webhookLimiter"
  key_links:
    - from: "src/middleware/rateLimiter.ts"
      to: "src/config/redis.ts"
      via: "Redis client"
      pattern: "redisClient"
    - from: "src/index.ts"
      to: "src/middleware/rateLimiter.ts"
      via: "middleware application"
      pattern: "apiRateLimiter"
---

<objective>
Implement Redis-backed rate limiting for all API endpoints with tiered limits for webhooks, authenticated APIs, and public endpoints.

Purpose: Current rate limiting is memory-based, which doesn't work across multiple server instances and loses state on restart. Production requires Redis-backed rate limiting for consistent enforcement.

Output: Redis-backed rate limiters with appropriate tiers and standard rate limit headers on all responses.
</objective>

<execution_context>
@/Users/tvellore/.claude/get-shit-done/workflows/execute-plan.md
@/Users/tvellore/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Existing rate limiter
@src/middleware/rateLimiter.ts
# Redis configuration
@src/config/redis.ts
# Main app entry - route registration
@src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Redis-backed rate limiters with tiers</name>
  <files>
    src/middleware/rateLimiter.ts
    src/config/redis.ts
  </files>
  <action>
    Refactor src/middleware/rateLimiter.ts to use Redis:

    1. Import RateLimiterRedis from rate-limiter-flexible (already installed)
    2. Import Redis client from src/config/redis.ts (verify ioredis client export)

    3. Create tiered rate limiters:
       ```typescript
       // Webhook tier: 1000 req/min per IP (high volume from monitoring tools)
       const webhookLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:webhook',
         points: 1000,
         duration: 60,
       });

       // API tier: 500 req/min per authenticated user
       const apiLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:api',
         points: 500,
         duration: 60,
       });

       // Public tier: 100 req/min per IP (unauthenticated)
       const publicLimiter = new RateLimiterRedis({
         storeClient: redisClient,
         keyPrefix: 'ratelimit:public',
         points: 100,
         duration: 60,
       });

       // Keep memory-based break-glass limiter (emergency fallback if Redis down)
       ```

    4. Verify src/config/redis.ts exports a usable Redis client:
       - Check if ioredis client is exported
       - If not, add export for rate limiter use

    5. Add graceful fallback: if Redis unavailable, log warning and allow request
       (avoid blocking all traffic on Redis failure)
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check rate limiters use RateLimiterRedis
    Verify redis client import works
  </verify>
  <done>
    Three Redis-backed rate limiters created with appropriate limits per tier.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create rate limit middleware with headers</name>
  <files>
    src/middleware/rateLimiter.ts
  </files>
  <action>
    Create Express middleware functions that:

    1. Apply correct limiter based on route/auth status:
       ```typescript
       export function webhookRateLimiter(req, res, next) {
         const key = req.ip || 'unknown';
         webhookLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 1000);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'webhook');
           });
       }

       export function apiRateLimiter(req, res, next) {
         // Use user ID for authenticated requests, IP for anonymous
         const key = req.user?.id || req.ip || 'unknown';
         apiLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 500);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'api');
           });
       }

       export function publicRateLimiter(req, res, next) {
         const key = req.ip || 'unknown';
         publicLimiter.consume(key)
           .then((rateLimiterRes) => {
             setRateLimitHeaders(res, rateLimiterRes, 100);
             next();
           })
           .catch((rateLimiterRes) => {
             handleRateLimitExceeded(req, res, rateLimiterRes, 'public');
           });
       }
       ```

    2. Set standard rate limit headers:
       ```typescript
       function setRateLimitHeaders(res, rateLimiterRes, limit) {
         res.set({
           'X-RateLimit-Limit': limit,
           'X-RateLimit-Remaining': rateLimiterRes.remainingPoints,
           'X-RateLimit-Reset': Math.ceil(Date.now() / 1000) + Math.ceil(rateLimiterRes.msBeforeNext / 1000)
         });
       }
       ```

    3. Handle rate limit exceeded:
       ```typescript
       async function handleRateLimitExceeded(req, res, rateLimiterRes, tier) {
         const secs = Math.ceil(rateLimiterRes.msBeforeNext / 1000);

         await auditService.log({
           action: 'rate_limit.exceeded',
           severity: 'WARN',
           userId: req.user?.id,
           metadata: {
             tier,
             ip: req.ip,
             path: req.path,
             retryAfter: secs
           }
         });

         res.set({
           'Retry-After': secs,
           'X-RateLimit-Limit': limit,
           'X-RateLimit-Remaining': 0,
           'X-RateLimit-Reset': Math.ceil(Date.now() / 1000) + secs
         });

         res.status(429).json({
           error: 'Too Many Requests',
           message: 'Rate limit exceeded',
           retryAfter: secs
         });
       }
       ```
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check all three middleware functions exported
    Verify headers are set correctly
  </verify>
  <done>
    Rate limit middleware functions with standard headers and audit logging.
  </done>
</task>

<task type="auto">
  <name>Task 3: Apply rate limiters to routes in src/index.ts</name>
  <files>
    src/index.ts
    src/webhooks/alert-receiver.ts
  </files>
  <action>
    Apply rate limiters to appropriate routes. The app uses direct route mounting in src/index.ts.

    1. In src/index.ts, add import at top:
       ```typescript
       import { apiRateLimiter, publicRateLimiter } from './middleware/rateLimiter.js';
       ```

    2. Apply apiRateLimiter to API routes. Add BEFORE the individual /api/* route registrations (around line 143):
       ```typescript
       // Rate limit all API routes (authenticated tier: 500 req/min per user)
       app.use('/api', apiRateLimiter);

       // API routes (existing)
       app.use('/api/audit', auditRouter);
       // ... rest of /api/* routes
       ```

    3. Apply publicRateLimiter to public endpoints. Add BEFORE the public route handlers:
       ```typescript
       // Rate limit public endpoints (100 req/min per IP)
       app.use('/status', publicRateLimiter);  // Before statusPublicRoutes
       app.use('/health', publicRateLimiter);  // Before health check handler
       ```

    4. Update src/webhooks/alert-receiver.ts:
       - Import webhookRateLimiter from middleware
       - Add as first middleware in the router:
         ```typescript
         import { webhookRateLimiter } from '../middleware/rateLimiter.js';

         // At top of router setup, before other middleware
         router.use(webhookRateLimiter);
         ```

    5. Route classification summary:
       - /webhooks/alerts/*: webhookRateLimiter (1000/min per IP) - in alert-receiver.ts
       - /api/*: apiRateLimiter (500/min per user) - in src/index.ts
       - /status/*, /health: publicRateLimiter (100/min per IP) - in src/index.ts
       - /auth/*: Keep existing loginRateLimiter for break-glass protection

    6. Do NOT apply rate limiting to these routes (they have their own auth/protection):
       - /webhooks/okta, /webhooks/slack, /webhooks/twilio (signature-verified)
       - /scim/v2 (SCIM token auth)
       - /magic (token-based access)

    7. Add comments documenting rate limit tiers for future reference
  </action>
  <verify>
    Run `npm run build` - no TypeScript errors
    Check webhook routes use webhookRateLimiter
    Check API routes use apiRateLimiter
    Manual test: make requests and verify X-RateLimit-* headers in response
  </verify>
  <done>
    Rate limiters applied to all routes with appropriate tiers.
  </done>
</task>

</tasks>

<verification>
1. Rate limiters use Redis (not memory)
2. Three tiers configured correctly
3. Standard headers on all responses
4. 429 response on limit exceeded
5. Audit logging for violations
6. TypeScript builds without errors
</verification>

<success_criteria>
- [ ] RateLimiterRedis used for all tiers
- [ ] Webhooks: 1000 req/min per IP
- [ ] API: 500 req/min per user
- [ ] Public: 100 req/min per IP
- [ ] X-RateLimit-* headers on responses
- [ ] Violations logged to audit system
- [ ] Graceful fallback on Redis failure
</success_criteria>

<output>
After completion, create `.planning/phases/14-production-hardening/14-05-SUMMARY.md`
</output>
